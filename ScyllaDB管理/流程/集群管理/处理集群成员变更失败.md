## 处理集群成员变更失败
在集群成员变更（初始化、下线、删除和替换）的过程中可能会发生失败，比如掉电。对于这种情况，应该尽快让集群恢复到一致的状态，而且在此前不可再进行成员变更操作

举个例子，某节点在下线过程中崩溃，此时集群可能仍然认为该节点还属于集群子节点，而该节点已经无法恢复服务并与集群其他节点通信了。这种情况十分罕见，需要节点在特定的时间段崩溃才会触发，即在数据流传输完毕之后，目标节点通知集群其他节点自己已离开集群之前

### 处理初始化失败
如果新节点在加入集群的过程中初始化失败，可以尝试重启该节点并触发初始化

如果持续失败，或者你决定不再初始化节点，请按照[成员更改失败后的清理](https://opensource.docs.scylladb.com/stable/operating-scylla/procedures/cluster-management/handling-membership-change-failures.html#cleaning-up-after-change)章节中的说明进行操作，最后清除节点的数据目录并根据意愿尝试再次初始化它

### 处理下线失败
有两种情况

1. 最有可能的是，故障发生在节点尝试离开令牌环之前的数据修复/流处理阶段。在尝试下线的节点的日志中查找包含“离开令牌环”的日志消息，例如：
    ```
    INFO  2023-03-14 13:08:38,323 [shard 0] storage_service - decommission[5b2e752e-964d-4f36-871f-254491f4e8cc]: leaving token ring
    ```
    如果该消息不存在，则故障发生在节点尝试离开令牌环之前。在这种情况下，只需重新启动节点并尝试再次下线

2. 如果存在该消息，则节点在发生故障之前尝试离开令牌环，它可能仅部分离开了集群。请勿尝试重新启动节点，相反必须确保节点已失效，并使用[removenode操作](https://opensource.docs.scylladb.com/stable/operating-scylla/nodetool-commands/removenode.html)删除任何剩余部分，同时请参阅[成员更改失败后的清理](https://opensource.docs.scylladb.com/stable/operating-scylla/procedures/cluster-management/handling-membership-change-failures.html#cleaning-up-after-change)。在此类故障发生后如果尝试重新启动节点会导致不可预知的结果，可能会正常重新启动，可能会拒绝重新启动，甚至可能尝试重新初始化

如果无法访问节点的日志，请假设第二种情况（节点可能已尝试离开令牌环），不要尝试重新启动节点，而是按照[成员更改失败后的清理](https://opensource.docs.scylladb.com/stable/operating-scylla/procedures/cluster-management/handling-membership-change-failures.html#cleaning-up-after-change)章节进行操作

### 处理删除失败
对于这种失败，就重试删除即可

如果不小心丢失了尝试删除的节点的主机ID，请按照[成员更改失败后的清理](https://opensource.docs.scylladb.com/stable/operating-scylla/procedures/cluster-management/handling-membership-change-failures.html#cleaning-up-after-change)中的说明进行操作

### 处理替换失败
替换是初始化的一种特例，目的是试图取代另一个死节点。可以通过重新启动替换节点来重试失败的替换操作

如果持续失败，或者你决定不再执行替换，请按照[成员更改失败后的清理](https://opensource.docs.scylladb.com/stable/operating-scylla/procedures/cluster-management/handling-membership-change-failures.html#cleaning-up-after-change)章节中的说明删除替换节点的剩余部分，最后清除节点的数据目录并根据意愿尝试再次替换，也可以使用[removenode](https://opensource.docs.scylladb.com/stable/operating-scylla/nodetool-commands/removenode.html)删除尝试替换的死节点，并执行常规初始化

### 成员变更失败后的清理
当成员更改失败后，集群可能保留了新加入/删除的节点的部分信息，即其他节点会认为该节点属于集群成员。清除这些"幽灵"成员是很重要的，它们的存在会降低集群的可用性、性能或阻碍后续的成员变更

你需要确定任何潜在的"幽灵"成员的主机ID，然后使用[removenode](https://opensource.docs.scylladb.com/stable/operating-scylla/nodetool-commands/removenode.html)操作将其删除。注意替换失败后，可能存在两个不同的主机ID：新的替换节点和尝试替换的旧节点（可以仅删除新节点，然后再次尝试替换旧节点）

#### 第一步：确定"幽灵"成员的主机ID
 - 初始化失败后，你需要确定尝试初始化的节点的主机ID，如果它已经生成了主机ID（如果在过程的早期失败，则可能尚未生成主机ID，在这种情况下无需删除任何内容）。在节点的日志中查找包含`system_keyspace - Setting local host id to`的消息，该消息将包含节点的主机ID，例如：`system_keyspace - Setting local host id to f180b78b-6094-434d-8432-7327f4d4b38d`。如果您无权访问节点的日志，请阅读下面的通用方法
 - 停用失败后，你需要确定尝试停用的节点的主机ID，可以像初始化失败一样搜索节点的日志（见上文），也可以使用下面的通用方法
 - 删除失败后，你需要确定尝试删除的节点的主机ID，因为执行`removenode`需要主机ID，所以你应该已经获得主机ID，如果意外丢失了，请阅读下面的通用方法
 - 替换失败后，你需要确定替换节点的主机ID，像初始化失败一样搜索节点的日志（见上文），或者使用下面的通用方法。你可能还希望确定被替换节点的主机ID，以便在清理完替换节点后再次尝试替换它，或者使用`nodetool removenode`将其删除。如果使用`replace_node_first_boot`选项执行替换，则应已知被替换节点的主机ID

如果无法使用上述方法确定"幽灵"成员的主机ID，请使用下面的通用方法。根据集群中是否启用了Raft，方法会有所不同
- 启用了Raft

    1. 确保没有正在进行的成员更改
    2. 在某个节点上执行以下CQL查询以检索Raft group 0 ID：

        ```
        select value from system.scylla_local where key = 'raft_group0_id'
        ```
        举个例子：
        ```
        cqlsh> select value from system.scylla_local where key = 'raft_group0_id';

        value
        --------------------------------------
        607fef80-c276-11ed-a6f6-3075f294cc65
        ```
    3. 使用获取的Raft group 0 ID并执行以下查询来查询所有集群成员的主机ID（包括"幽灵"成员）的集合：

        ```
        select server_id from system.raft_state where group_id = <group0_id>
        ```
        <group0_id>替换为您获取的group 0 ID，例如：
        ```
        cqlsh> select server_id from system.raft_state where group_id = 607fef80-c276-11ed-a6f6-3075f294cc65;

        server_id
        --------------------------------------
        26a9badc-6e96-4b86-a8df-5173e5ab47fe
        7991e7f5-692e-45a0-8ae5-438be5bc7c4f
        aff11c6d-fbe7-4395-b7ca-3912d7dba2c6
        ```
    4. 执行以下CQL查询，获取所有令牌环成员的主机ID：

        ```
        select peer, host_id, up from system.cluster_status;
        ```
        举个例子：
        ```
        cqlsh> select peer, host_id, up from system.cluster_status;

        peer      | host_id                              | up
        -----------+--------------------------------------+-------
        127.0.0.3 |                                 null | False
        127.0.0.1 | 26a9badc-6e96-4b86-a8df-5173e5ab47fe |  True
        127.0.0.2 | 7991e7f5-692e-45a0-8ae5-438be5bc7c4f |  True
        ```
        以上有点类似`nodetool status`的结果

        up列查看哪些节点已关闭，peer列则用于查看其IP地址

        在这个例子中，其中一个节点试图下线，在它离开令牌环之后，离开Raft组之前崩溃了，则其对应的`system.cluster_status`查询中，host_id将为null，如上所述直到群集重新启动
    5. 以下情况满足主机ID属于"幽灵"成员

        - 它出现在`system.raft_state`查询中，但不显示在`system.cluster_status`查询中
        - 或者它在`system.cluster_status`查询中，但与群集中的剩余节点都对应不上

    在我们的示例中，"幽灵"成员的主机ID是`aff11c6d-fbe7-4395-b7ca-3912d7dba2c6`，因为它出现在`system.raft_state`查询中，但未出现在`system.cluster_status`查询中

    如果不确定`system.cluster_status`查询中的给定行是否与集群中的某个节点相对应，可以连接到集群中的每个节点，然后执行`select host_id from system.local`（或搜索节点的日志）以获取该节点的主机ID，从而收集集群中所有节点的主机ID。然后检查`system.cluster_status`查询中的每个主机ID是否在收集的主机ID中，如果不是则为"幽灵"成员

    一个好的经验法则是查看标记为`down`的成员（`system.cluster_status`中up = False），"幽灵"成员最终会被集群的其余成员标记为down。但请记住，如果真实成员已关闭或与集群的其余部分发生了分区，则也可能被标记为`down`

- 未启用Raft

    1. 确保没有正在进行的成员更改
    2. 执行以下CQL查询，获取所有令牌环成员的主机ID：

        ```
        select peer, host_id, up from system.cluster_status;
        ```
        举个例子：
        ```
        cqlsh> select peer, host_id, up from system.cluster_status;

        peer      | host_id                              | up
        -----------+--------------------------------------+-------
        127.0.0.3 | 42405b3b-487e-4759-8590-ddb9bdcebdc5 | False
        127.0.0.1 | 4e3ee715-528f-4dc9-b10f-7cf294655a9e |  True
        127.0.0.2 | 225a80d0-633d-45d2-afeb-a5fa422c9bd5 |  True
        ```
        以上有点类似`nodetool status`的结果

        up列查看哪些节点已关闭

        在这个例子中，3个节点中的1个尝试停用，但在离开令牌环时崩溃。节点处于非正常状态并将拒绝重新启动，但其他节点仍视其为正常成员，所以我们将不得不使用`removenode`进行清理
    3. 如果主机ID出现在`system.cluster_status`查询中，但与集群中的所有节点都对应不上，则该主机ID属于"幽灵"成员

        如果不确定`system.cluster_status`查询中的给定行是否与集群中的某个节点相对应，可以连接到集群中的每个节点，然后执行`select host_id from system.local`（或搜索节点的日志）以获取该节点的主机ID，从而收集集群中所有节点的主机ID。然后检查`system.cluster_status`查询中的每个主机ID是否在收集的主机ID中，如果不是则为"幽灵"成员

        一个好的经验法则是查看标记为`down`的成员（`system.cluster_status`中up = False），"幽灵"成员最终会被集群的其余成员标记为down。但请记住，如果真实成员已关闭或与集群的其余部分发生了分区，则也可能被标记为`down`

        在我们的示例中，"幽灵"成员的主机ID为`42405b3b-487e-4759-8590-ddb9bdcebdc5`，因为它是唯一标记为关闭的成员，我们可以验证`system.cluster_status`中出现的另外两行是否属于集群中的其余2个节点

在某些情况下，即使在拓扑更改失败后，也可能没有留下"幽灵"成员，例如，如果初始化节点在过程的早期崩溃，或者下线节点在提交成员身份更改后但在完成自己的关闭步骤之前崩溃

如果存在任何"幽灵"成员，请继续执行下一步

#### 第二步：移除"幽灵"成员
给定"幽灵"成员的主机ID，你可以使用`removenode`删除它们，按照[removenode操作文档](https://opensource.docs.scylladb.com/stable/operating-scylla/nodetool-commands/removenode.html)进行操作

如果在成员更改失败后执行`removenode`的速度过快，则可能会弹出以下内容的错误：
```
nodetool: Scylla API server HTTP POST to URL '/storage_service/remove_node' failed: seastar::rpc::remote_verb_error (node_ops_cmd_check: Node 127.0.0.2 rejected node_ops_cmd=removenode_abort from node=127.0.0.1 with ops_uuid=0ba0a5ab-efbd-4801-a31c-034b5f55487c, pending_node_ops={b47523f2-de6a-4c38-8490-39127dba6b6a}, pending node ops is in progress)
```
在这种情况下，只需等待2分钟，然后再次尝试`removenode`

如果`removenode`返回如下错误：
```
nodetool: Scylla API server HTTP POST to URL '/storage_service/remove_node' failed: std::runtime_error (removenode[12e7e05b-d1ae-4978-b6a6-de0066aa80d8]: Host ID 42405b3b-487e-4759-8590-ddb9bdcebdc5 not found in the cluster)
```
并且确定提供的是正确的主机ID，这意味着该成员已被删除，不必在删除之后再进行清理